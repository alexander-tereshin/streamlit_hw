1. Развертывание PostgreSQL на VPS:
На VPS была успешно установлена и настроена PostgreSQL. База данных была сконфигурирована и наполнена данными.
2. Подготовка данных:
Используя библиотеку scikit-learn, был создан ColumnTransformer, определяющий два этапа обработки данных: числовые (num_cols) и категориальные (cat_cols).
3. Обработка числовых данных:
Для числовых данных был применен StandardScaler.
4. Обработка категориальных данных:
Для категориальных данных был использован OneHotEncoder.
5. Построение конвейера (pipeline):
С использованием Pipeline были объединены обработка данных (preprocessor) и классификатор (LogisticRegression()) в один конвейер. Это обеспечило последовательное применение всех этапов обработки данных и обучения модели.
6. Выбор классификатора:
Логистическая регрессия (Logistic Regression) была выбрана в качестве классификатора.
7. Деплой на Streamlit:
После успешного обучения модели и настройки конвейера, было проведено деплой приложения на Streamlit. В результате проведенных шагов был создан инструмент для обработки данных, обучения модели и предсказания результатов, интегрированный с удаленной базой данных PostgreSQL и доступный через интерфейс Streamlit.